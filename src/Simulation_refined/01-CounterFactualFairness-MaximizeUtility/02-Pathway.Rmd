---
title: "Simulation 03"
author: "Hamed Nilforoshan"
date: "2/22/2021"
output:
  github_document:
    pandoc_args: --webtex
---


```{r setup, include=FALSE}
library(sigmoid)
library(tidymodels)
library(tidyverse)
library(furrr)
library(nloptr)
library(BBmisc)


# Set number of workers.
plan(multicore, workers = 4)

# Set the ggplot theme.
theme_set(theme_bw(base_size = 20))
```

## Overview

We construct a stylized example illustrating the sub-optimal outcomes of Wang and Blei's fairness definitions (Affirmative Action and Equal Opportunity) on utility. 

## Setup

Prints out the results of a given admissions method
```{r trace_results}

  print_results <- function(DF_TEST, DF_TEST_COL, N_ADMIT, RESULT_NAME){
    DF_TEST<-DF_TEST[order(DF_TEST_COL,decreasing=TRUE),]

    cat("Result Type: ", RESULT_NAME,'\n')
    cat("Lives Saved: ", sum(head(DF_TEST,n=N_ADMIT)$L_p),'\n')
    cat("Boards Passages: ", sum(head(DF_TEST,n=N_ADMIT)$B_p),'\n')
    cat("Diverse Admits: ", sum(head(DF_TEST,n=N_ADMIT)$D_p),'\n')
   
  }

  return_results <- function(DF_TEST, DF_TEST_COL, N_ADMIT, RESULT_NAME){
    DF_TEST<-DF_TEST[order(DF_TEST_COL,decreasing=TRUE),]
    return(c(RESULT_NAME, sum(head(DF_TEST,n=N_ADMIT)$L_p), sum(head(DF_TEST,n=N_ADMIT)$D_p)/N_ADMIT, sum(head(DF_TEST,n=N_ADMIT)$B_p)))
  }




```


A "book of life" is a draw of each potential outcome for a population of a given
size. We'll define a function that generates a book of life for a given set of
parameters. T

```{r book_of_life}

gen_book_of_life <- function(
  pop_size,
  frac_black,
  e_0,
  e_r, 
  e_noise,
  m_0,
  m_e,
  m_noise,
  t_0,
  t_m,
  t_e,
  t_noise,
  a_0,
  a_t,
  a_r,
  i_noise,
  A_NORMALIZE_MIN, 
  A_NORMALIZE_MAX,
  ...
) {
  
  # Define the structural equations.
  f_E <- function(r_i, noise){
    return(round(e_0 + e_r*r_i + noise,digits=1))
  ### Hans:  to get not 1 or 0
  ### return(round(e_0 + e_r*r_i + (1+r_i)*noise,digits=1))

  }
  
  f_M <- function(e_i, noise){
    return(round(m_0 + m_e*e_i + noise,digits=1))
  }

  f_T <- function(m_i, e_i, noise){
  #Hans: less controversial (to get not 1 or 0)
  return(round(t_0 + t_m*m_i + t_e*e_i + 0.01*e_i*m_i + noise ,digits=0))

  #  return(round(t_0 + t_m*m_i + t_e*e_i + noise ,digits=1))
### Hans: to get not 1 or 0 
 #   return(round(t_0 + t_m*m_i + t_e*e_i^2 + noise ,digits=1))

  }
  
  f_A_raw <- function(t_i, r_i, i_i){
    return(a_t*t_i + a_r*r_i + a_0 + i_i)
    #return(normalize(a_t*t_i + a_r*r_i + a_0, method='range',range = c(A_NORMALIZE_MIN, A_NORMALIZE_MAX)))
    #return(round(sigmoid(a_t*t_i + a_r*r_i- a_0), digits = 0))
  }
  
  f_A <- function(t_i, r_i, i_i){
    return(sigmoid(a_t*t_i + a_r*r_i + a_0 + i_i))
    #return(sigmoid(normalize(a_t*t_i + a_r*r_i + a_0, method='range',range = c(A_NORMALIZE_MIN, A_NORMALIZE_MAX))))
  }

  

  # Generate the book of life.
  book_of_life <- tibble(
      # Generate the exogenous variables.
      R = as.numeric(as.integer(rbernoulli(pop_size, frac_black))), # Race (Black=1, White=0)
      
      I_noise = rnorm(pop_size, mean = 0, sd = i_noise),
      
      E_noise = rnorm(pop_size, mean = 0, sd = e_noise), #Educational opportunities
      E_black = f_E(1,noise = E_noise),
      E_white = f_E(0,noise = E_noise),
      
      M_noise = rnorm(pop_size, mean = 0, sd = m_noise), #Medical school preparation
      M_black = f_M(E_black, noise=M_noise),
      M_white = f_M(E_white, noise=M_noise),

      # Generate the endogenous variables.
      T_noise = rnorm(pop_size, mean = 0, sd = t_noise), #Medical school preparation
      T_black = f_T(M_black, E_black, noise=T_noise),
      T_white = f_T(M_white, E_white, noise=T_noise),
      T_white_star = f_T(M_black, E_white, noise=T_noise),
      T_black_star = f_T(M_white, E_black, noise=T_noise),
      

      
      E = if_else(R==1,E_black,E_white),
      M = if_else(R==1,M_black,M_white),
      T = if_else(R==1,T_black,T_white),
      
      
      # M -- isnt bimodal
      # M -- scale so bottom half is negative
      # Don't worry about population level diff being unrealistic #1 priority is qualitative the results make sense 

      A_raw = f_A_raw(T, R,I_noise), # Admissions Committee Decision 
      A_raw_black = f_A_raw(T_black, 1,I_noise), # Admissions Committee Decision 
      A_raw_white = f_A_raw(T_white, 0,I_noise), # Admissions Committee Decision 

      A_prob = f_A(T,R,I_noise),
      #A_prob_black = f_A(T_black, 1), # Admissions Committee Decision,
      #A_prob_white = f_A(T_white, 0), # Admissions Committee Decision 
      A = as.integer(runif(pop_size,min=0,max=1) < A_prob),
      
      # Generate potential outcomes
      L_p = M, # Lives saved if admitted
      B_p = ifelse(M > quantile(M,BOARD_PASS_CUTOFF), 1,0),
      D_p = R , # Added diversity if admitted  
      
      # Generate observed outcomes
      L_o = L_p * A, # Lives saved observed
      B_o = B_p * A, # Lives saved observed
      D_o = D_p * A  # Added diversity observed 
      
  )
}
```


## Initialize parameters and books of life
We initialize the training population size for the book of life, the fraction of the population that is a minority (black), and the number of counterfactual draws when calculating affirmative action decisions.

We then initial two books of life. One is for training our models, and the second is for testing what happens when the models are applied to a new, unseen dataset

```{r init}
POP_SIZE = 10000000*0.1
POP_SIZE_TEST = 100000*0.1
POP_SIZE_TEST_ADMIT = 2500
FRAC_BLACK = 0.2
COUNTER_FACTUAL_SAMPLE = 10000
BOARD_PASS_CUTOFF = 0.75

E_0 = 50+100
E_R = -50
E_NOISE = 30
M_0 = 25+100
M_E = 0.5
M_NOISE = 20
T_0 = 0
T_M = 0.5
T_E = 0.5


T_NOISE = 5
I_NOISE = 0.5
A_0 = -2.0
A_T = 0.04
A_R = -1


# OG
E_0 = 50
E_R = -50
E_NOISE = 30
M_0 = 25
M_E = 0.5
M_NOISE = 20
T_0 = 0
T_M = 0.5
T_E = 0.5
T_NOISE = 5
I_NOISE = 0.5
A_0 = -2.0
A_T = 0.04
A_R = -1


df_train <-gen_book_of_life(pop_size=POP_SIZE,
                            frac_black=FRAC_BLACK,
                            e_0=E_0,
                            e_r=E_R,
                            e_noise=E_NOISE,
                            m_0=M_0,
                            m_e=M_E,
                            m_noise=M_NOISE,
                            t_0=T_0,
                            t_m=T_M,
                            t_e=T_E,
                            t_noise=T_NOISE,
                            i_noise=I_NOISE,
                            a_0=A_0,
                            a_t=A_T,
                            a_r=A_R)

df_test <-gen_book_of_life(pop_size=POP_SIZE_TEST,
                            frac_black=FRAC_BLACK,
                            e_0=E_0,
                            e_r=E_R,
                            e_noise=E_NOISE,
                            m_0=M_0,
                            m_e=M_E,
                            m_noise=M_NOISE,
                            t_0=T_0,
                            t_m=T_M,
                            t_e=T_E,
                            t_noise=T_NOISE,
                            i_noise=I_NOISE,
                            a_0=A_0,
                            a_t=A_T,
                            a_r=A_R)


POP_SIZE_TEST_ADMIT = sum(df_test$A)

df_train_ = filter(df_train, A == 1 )
BLACK_ADMITS = sum(df_train_$R)


HUMAN_RESULTS = return_results(df_test, df_test$A, POP_SIZE_TEST_ADMIT, 'Human Decision')
HUMAN_RESULTS_NON_RANDOM = return_results(df_test, df_test$A_prob, POP_SIZE_TEST_ADMIT, 'Human Decision')

```


## Use the outcomes model

```{r ml_outcomes}
df_train_ = filter(df_train, A == 1 )

ml_outcomes <- glm(B_p ~ T+R+T*R, data = df_train_)

summary(ml_outcomes)

BOOST = 0.0

df_test$ml_outcomes = predict(ml_outcomes,df_test) + BOOST*df_test$R



df_test_black = tibble(df_test)
df_test_black$R=1
df_test_black$T=df_test_black$T_black
df_test_white = tibble(df_test)
df_test_white$R=0
df_test_white$T=df_test_white$T_white

df_test$ml_outcomes_black = predict(ml_outcomes,df_test_black) + BOOST*df_test_black$R
df_test$ml_outcomes_white = predict(ml_outcomes,df_test_white)  + BOOST*df_test_white$R


THRESHOLD = quantile(df_test$ml_outcomes, 1- POP_SIZE_TEST_ADMIT/POP_SIZE_TEST) 
df_test$ml_outcomes_decision = ifelse(df_test$ml_outcomes >= THRESHOLD,1.0,0.0)
df_test$ml_outcomes_decision_black = ifelse(df_test$ml_outcomes_black >= THRESHOLD,1.0,0.0)
df_test$ml_outcomes_decision_white = ifelse(df_test$ml_outcomes_white >= THRESHOLD,1.0,0.0)
df_test$ml_outcomes_decision_counterfactual = ifelse(df_test$R==1,df_test$ml_outcomes_decision_white, df_test$ml_outcomes_decision_black)

df_test$R = sapply(df_test$R, as.numeric)

df_check <-  df_test%>% select(R, T, ml_outcomes_decision) %>%
 group_by(R, T) %>%
 summarize(admit_rate = mean(ml_outcomes_decision))

df_check_ <-  df_test%>% select(R, T, ml_outcomes_decision_counterfactual) %>%
 group_by(R, T) %>%
 summarize(admit_rate = mean(ml_outcomes_decision_counterfactual)) %>% setNames(paste0('cf.', names(.)))

df_c <- left_join(df_check, df_check_, by = c("R" = "cf.R", "T" = "cf.T"))


ggplot(df_c) +
geom_line(aes(x = T, y = cf.admit_rate), color = "steelblue", linetype="twodash") + 
geom_line(aes(x = T, y = admit_rate), color = "darkred") + 
facet_grid(c("R")) 


ML_BOOST_2 = return_results(df_test, df_test$ml_outcomes, POP_SIZE_TEST_ADMIT, 'BLACK + 0.36')



CF_UNFAIRNESS = mean(abs(df_c$'admit_rate' - df_c$'cf.admit_rate'))




print_results(df_test, df_test$ml_outcomes, POP_SIZE_TEST_ADMIT, 'ML_Outcomes')

summary(ml_outcomes)

df_test$ml_outcomes_div = df_test$ml_outcomes + 0.20*df_test$R

ML_BOOST_2 = return_results(df_test, df_test$ml_outcomes, POP_SIZE_TEST_ADMIT, 'BLACK + 0.35')



ML_MAX_BOARDS_PASSAGE = return_results(df_test, df_test$ml_outcomes, POP_SIZE_TEST_ADMIT, 'Max Boards Passage')



ML_MAX_UTILITY = return_results(df_test, df_test$ml_outcomes_div, POP_SIZE_TEST_ADMIT, 'Max Utility')


write.csv(df_test,'./df_test_pathway.csv')

```

## Use the outcomes model with diversity constraint

```{r ml_outcomes_diverse}

N=round(POP_SIZE_TEST_ADMIT*FRAC_BLACK)

```



## Calculate if a decision policy is Counterfactually Fair 

```{r ml_eo_fair}







cfCheck <- function(df_check) {
  B_p = 'B_p'
  R = 'R'
  A = 'A'
  A_max = 'A_max'
  E='E'
  T='T'
  
 
 df_check_ <- df_check[,c(A_max, R, B_p, T)]  %>% 
 group_by(R, T, B_p) %>%
 summarize(admit_rate = mean(A_max))  %>% pivot_wider( names_from = R, values_from = admit_rate)  %>% drop_na()
 return(mean(df_check_$'0' - df_check_$'1'))
  
  
}



```

## Draw the pareto curve

```{r pareto_curve}

MAX_BLACK_ADMIT = POP_SIZE_TEST_ADMIT * FRAC_BLACK
pareto_ideal = NULL

for (num_black_admit in seq(from=1,to=as.integer(N+10),by=3)){
  cat(num_black_admit)
  frac_black = num_black_admit/POP_SIZE_TEST_ADMIT
  
  df_test_black<- df_test[order(df_test$L_p,decreasing=TRUE),] %>% filter( R == 1 )
  df_test_white<- df_test[order(df_test$L_p,decreasing=TRUE),] %>% filter( R == 0 )
  lives_saved = sum(head(df_test_black,n=num_black_admit)$B_p) + sum(head(df_test_white,n=POP_SIZE_TEST_ADMIT-num_black_admit)$B_p) 
  
  df_test_black<- df_test[order(df_test$ml_outcomes,decreasing=TRUE),] %>% filter( R == 1 )
  df_test_white<- df_test[order(df_test$ml_outcomes,decreasing=TRUE),] %>% filter( R == 0 )
  lives_saved_outcomes = sum(head(df_test_black,n=num_black_admit)$B_p) + sum(head(df_test_white,n=POP_SIZE_TEST_ADMIT-num_black_admit)$B_p) 
  
  pareto_ideal = rbind(pareto_ideal, data.frame(frac_black, lives_saved,lives_saved_outcomes))
}




# ggplot colors
peach <- "#F8766D"
purple <- "#C77CFF"
blue <- "#00BFC4"
green <- "#00BE6C"
browngreen <- "#A3A500"
transparency <- 0.4
labels = c("1", "2", "3", "4", "5")


random_x <- 0.1
random_y <- 280000 


p <- ggplot() +
  geom_line(data=pareto_ideal, aes(x=frac_black, y=lives_saved_outcomes, color='ML Outcomes (Given T, R)')) + 
  scale_x_continuous("% Black Admits", labels = scales::percent) + 
  ylab("# Boards Passages") +  
  
  geom_vline(xintercept = as.double(ML_BOOST_1[[3]]), linetype = "dashed", colour = green, alpha=transparency) +
  geom_hline(yintercept = as.double(ML_BOOST_1[[4]]), linetype = "dashed", colour = green, alpha=transparency) +
  geom_point(aes(x = as.double(ML_BOOST_1[[3]]), y = as.double(ML_BOOST_1[[4]])), color = green, size = 3) +
  annotate("text", x = as.double(ML_BOOST_1[[3]])+0.02, y = as.double(ML_BOOST_1[[4]]) + 2, label = ML_BOOST_1[[1]]) +

  geom_vline(xintercept = as.double(ML_BOOST_2[[3]]), linetype = "dashed", colour = browngreen, alpha=transparency) +
  geom_hline(yintercept = as.double(ML_BOOST_2[[4]]), linetype = "dashed", colour = browngreen, alpha=transparency) +
  geom_point(aes(x = as.double(ML_BOOST_2[[3]]), y = as.double(ML_BOOST_2[[4]])), color = browngreen, size = 3) +
  annotate("text", x = as.double(ML_BOOST_2[[3]])-0.05, y = as.double(ML_BOOST_2[[4]]) + 2, label = ML_BOOST_2[[1]]) +


  
  geom_vline(xintercept = as.double(ML_MAX_BOARDS_PASSAGE[[3]]), linetype = "dashed", colour = peach, alpha=transparency) +
  geom_hline(yintercept = as.double(ML_MAX_BOARDS_PASSAGE[[4]]), linetype = "dashed", colour = peach, alpha=transparency) +
  geom_point(aes(x = as.double(ML_MAX_BOARDS_PASSAGE[[3]]), y = as.double(ML_MAX_BOARDS_PASSAGE[[4]])), color = peach, size = 3) +
  annotate("text", x = as.double(ML_MAX_BOARDS_PASSAGE[[3]])+0.052, y = as.double(ML_MAX_BOARDS_PASSAGE[[4]]) + 2, label = ML_MAX_BOARDS_PASSAGE[[1]]) +

  geom_vline(xintercept = as.double(ML_MAX_UTILITY[[3]]), linetype = "dashed", colour = blue, alpha=transparency) +
  geom_hline(yintercept = as.double(ML_MAX_UTILITY[[4]]), linetype = "dashed", colour = blue, alpha=transparency) +
  geom_point(aes(x = as.double(ML_MAX_UTILITY[[3]]), y = as.double(ML_MAX_UTILITY[[4]])), color = blue, size = 3) +
  annotate("text", x = as.double(ML_MAX_UTILITY[[3]])+0.03, y = as.double(ML_MAX_UTILITY[[4]]) + 2, label = ML_MAX_UTILITY[[1]]) +
  

  
  scale_color_manual(
      values = c(
           'Omniscient'="red",
           'ML Outcomes (Given T, R, E)'="blue",
           'ML Outcomes (Given T, R)'="violet" )) + 
  theme(legend.title = element_blank())
ggsave(plot=p, filename='./01.pdf', height=5, width=10)
p


```

